---
tags: [paper]
title: '1311.2901'
created: '2020-05-12T17:04:19.559Z'
modified: '2020-05-12T17:05:58.778Z'
---

# 1311.2901

## Visualizing and Understanding Convolutional Networks
- You attach a “Deconvnet” alongside the normal Convnet that does all the opposite operations. Once an image has been presented to the Convnet and features have been computed through all the layers, we select a specific activation in a layer and set all other activations in the layer to zero. We then pass the feature maps as input to the Decovnet and propagate (unpool, rectify, filter) until the input pixel space is reached. 
- Upper layers of CNNs are only seen to develop after a considerable number of epochs, demonstrating the need to let models train until they are fully converged.
- Trained CNNs should be invariant to translation, rotation and scaling, with only the first layer activations significantly changing when a shift is made.
- You can look at the activation output to make improvements. E.g. if the first layer filters are just a mix of low and high frequency information, reducing the first layer filter size could access the mid frequencies better.
- By obscuring different parts of the input image with a “grey” square and monitoring the top layers and output classifier you can see which parts of the image are the most important for classification.
