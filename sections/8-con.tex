\chapter{Summary and conclusion} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{chap:conclusion} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This thesis presented a range of work for the \chips neutrino detector R\&D project. \chips puts
forward a novel water Cherenkov based concept to counter the vast expense, increased complexity,
and long construction time expected from future long-baseline neutrino oscillation experiments. As
detailed, this feat is possible via a series of steps: deploying detector modules in bodies of
water on the Earth's surface rather than deep underground; using commercially available rather
than bespoke components wherever possible; and optimising photocathode coverage to study
accelerator beam neutrinos exclusively. These steps reduce the total cost per kt of sensitive mass
to between \$200k-\$300k and should allow for megaton scale detectors to become a reality.

Moreover, \chips detector modules are expected to be relatively easy to build, quick to deploy,
and can be upgraded once operational, making them a much more attractive proposition when
resources are constrained. It is hoped that future \chips detectors will be able to help answer
some of the key unsolved questions of neutrino physics, such as the mass hierarchy ambiguity and
the search for CP violation in neutrino oscillations.

During the summer of 2019 a \chips prototype, \chipsfive was deployed into the Wentworth 2W
disused mine pit in northern Minnesota, USA. Although \chipsfive is not yet fully proven and
future plans are still in flux, the amount of knowledge gained during its construction,
deployment, and initial commissioning can not be overstated. Alongside proving that a large \chips
detector module can be constructed and deployed, \chipsfive acted as a brilliant testbed for the
development of the \chips data acquisition system. 

Notably, the use of commercially available single-board Beaglebone machines and the open-source
Elasticsearch monitoring solution were found to be highly successful. Within both future \chips
detectors, and hopefully the broader experimental particle physics field, bespoke components
should continue to be phased out, with commercially available or open-source components used
instead. Not only does this drastically reduce the implementation effort required by collaborators
and cost, but leads to a much improved final result due to the pooling of resources. 

As is the case within the world around us, future \chips concept detectors will also make
ever-increasing use of modern deep learning techniques. This comes as a direct result of the
dramatic improvement in \chipsfive reconstruction and classification performance brought about by
the principal work presented in this thesis. Three forms of a Convolutional Neural Network have
been trained to reject cosmic muon events, classify beam events, and estimate neutrino energies,
all using only the raw detector event as input. This new approach replaces the standard
likelihood-based reconstruction and simple neural network classification, greatly increasing
generalisability and processing speed.

With the primary goal of selecting an efficient and pure appeared CC $\nu_{e}$ sample for which
the neutrino energy can be accurately determined, the new CNN-based approach is found to provide
excellent performance. Firstly, the vast cosmic muon background of \chipsfive is found to be
accepted by a factor of $<2.9\pm0.3\times10^{-6}$ (without the help of a veto), equivalent to
$<6\pm0.6$ cosmic muon events contaminating the beam sample per year, of which none are expected
to be classified as CC $\nu_{e}$ events.

Furthermore, the CC $\nu_{e}$ beam selection is found to select CC $\nu_{e}$ events with an
efficiency of $73.4\pm0.2\%$ and a purity of $70.9\pm0.6\%$, while the CC $\nu_{\mu}$ beam
selection achieves a $37.0\pm0.1\%$ and $96.0\pm0.1\%$ signal efficiency and purity, respectively.
The energy estimation networks achieve a (reco-true)/true FWHM neutrino energy resolution of
$24.0\pm0.3\%$ and $29.4\pm0.4\%$ for CC $\nu_{e}$ and CC $\nu_{\mu}$ selected signal events,
respectively. For ease of comparison, the performance metrics for which a value is available from
the old likelihood-based approach are summarised in \TableRef{tab:final_comparison}.

\begin{table}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{lrrr}
        Metric           & Likelihood-based (old) & CNN-based (new) & Percentage Change \\
        \midrule
        Max FOM-$\nu_{e}$            & $0.132\pm0.005$ & $0.519\pm0.004$ & $393\pm15\%$ \\
        CC $\nu_{e}$ Efficiency      & $34.7\pm0.8\%$  & $73.4\pm0.2\%$  & $212\pm5\%$  \\
        CC $\nu_{e}$ Purity          & $39.3\pm1.2\%$  & $70.9\pm0.6\%$  & $180\pm6\%$  \\
        \midrule
        QEL $\nu_{e}$ lepton E Res   & $33.3\pm4.1\%$  & $10.0\pm0.1\%$  & $30\pm4\%$ \\
        QEL $\nu_{\mu}$ lepton E Res & $23.2\pm3.7\%$  & $9.0\pm0.1\%$   & $39\pm6\%$ \\
    \end{tabular}
    }
    \caption[Performance comparison between the old likelihood-based approach and the new
        CNN-based approach]{Comparison of performance metrics between the old likelihood-based
        approach and the new CNN-based approach with the change (as a percentage) given for
        reference. The maximum FOM value metric alongside the signal efficiency and purity are
        given for the CC $\nu_{e}$ beam selection, as well as the QEL event lepton energy
        resolutions (defined as the FWHM of the (reco-true)/true energy distribution) for both CC
        $\nu_{e}$ and CC $\nu_{\mu}$ selected signal events.}
    \label{tab:final_comparison}
\end{table}

Not only are the trained CNNs found to provide excellent performance, but some insight into their
inner workings was achieved, and their outputs are found to be robust to a sample of tested
distributional changes in the input. These findings go some way to answering the common and
justified concern that they are too often used as a black box (input in, outputs out). Cherenkov
ring and Hough peak features are extracted from the input images, resulting in a learnt
representation of the inputs seen to have strong discriminating power between categories when
visualised using the t-SNE technique. Additionally, realistic modifications to the input hit times
and charges and the addition of random noise are all found to have a negligible effect on output
performance.

It is sincerely hoped that other water Cherenkov neutrino experiments will take inspiration from
and then build upon the work presented in this thesis for their own Convolutional Neural Network
implementations. Although the results presented in this work are incredibly compelling, there are
still clear avenues for exploration and improvement. These are all principally related to the
critical performance drivers outlined within this thesis. 

Firstly, generating the input event maps to focus on the underlying Cherenkov profiles is
incredibly important; therefore, any methodology to remove distortions further or more accurately
determine the interaction vertex position will be beneficial. Secondly, the distribution of events
(in energy or type) used within the training sample heavily impacts performance; thus, a
comprehensive study of this behaviour could optimise the sample used. Finally, multi-task learning
clearly shows promise, with further trial-and-error or a more generalised approach likely to
uncover additional valuable tasks. 

Likely, the true potential of these methods is just beginning to be realised. As is always the
case, only time will tell.